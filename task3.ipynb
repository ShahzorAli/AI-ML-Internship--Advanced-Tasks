{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hC8ieeJ7x4tc",
        "outputId": "30e967d7-29aa-4e30-e3d0-c8f7528e4008"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 1/5 | Loss: 104835612672.0000\n",
            "Epoch 2/5 | Loss: 104833452714.6667\n",
            "Epoch 3/5 | Loss: 104829995690.6667\n",
            "Epoch 4/5 | Loss: 104824190293.3333\n",
            "Epoch 5/5 | Loss: 104815741610.6667\n",
            "\n",
            "FINAL RESULTS\n",
            "MAE : 296780.43\n",
            "RMSE: 316869.48\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os, random, numpy as np, pandas as pd\n",
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms\n",
        "from torchvision.models import ResNet18_Weights\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "\n",
        "\n",
        "BASE_DIR = \"/content\"\n",
        "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
        "IMAGE_DIR = os.path.join(DATA_DIR, \"images\")\n",
        "CSV_PATH = os.path.join(DATA_DIR, \"housing.csv\")\n",
        "os.makedirs(IMAGE_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "if not os.path.exists(CSV_PATH):\n",
        "    print(\"Creating sample dataset...\")\n",
        "    rows = []\n",
        "\n",
        "    for i in range(30):\n",
        "        img_name = f\"house_{i}.jpg\"\n",
        "        img_path = os.path.join(IMAGE_DIR, img_name)\n",
        "\n",
        "        Image.new(\n",
        "            \"RGB\",\n",
        "            (256, 256),\n",
        "            (random.randint(0,255), random.randint(0,255), random.randint(0,255))\n",
        "        ).save(img_path)\n",
        "\n",
        "        rows.append({\n",
        "            \"image_name\": img_name,\n",
        "            \"area\": float(random.randint(800, 3000)),\n",
        "            \"bedrooms\": float(random.randint(1, 5)),\n",
        "            \"bathrooms\": float(random.randint(1, 4)),\n",
        "            \"location_score\": float(round(random.uniform(5, 9), 2)),\n",
        "            \"price\": float(random.randint(120000, 500000))\n",
        "        })\n",
        "\n",
        "    pd.DataFrame(rows).to_csv(CSV_PATH, index=False)\n",
        "    print(\"Dataset & images created\")\n",
        "\n",
        "\n",
        "class HousingDataset(Dataset):\n",
        "    def __init__(self, df, image_dir, transform):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "\n",
        "        image = Image.open(\n",
        "            os.path.join(self.image_dir, row[\"image_name\"])\n",
        "        ).convert(\"RGB\")\n",
        "        image = self.transform(image)\n",
        "\n",
        "\n",
        "        tabular = torch.tensor(\n",
        "            row[[\"area\",\"bedrooms\",\"bathrooms\",\"location_score\"]]\n",
        "            .astype(np.float32)\n",
        "            .values,\n",
        "            dtype=torch.float32\n",
        "        )\n",
        "\n",
        "        price = torch.tensor(float(row[\"price\"]), dtype=torch.float32)\n",
        "        return image, tabular, price\n",
        "\n",
        "\n",
        "class ImageEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        resnet = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
        "        self.features = nn.Sequential(*list(resnet.children())[:-1])\n",
        "        self.fc = nn.Linear(512, 128)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        return self.fc(x.view(x.size(0), -1))\n",
        "\n",
        "class TabularEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(4, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class MultimodalRegressor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.image_encoder = ImageEncoder()\n",
        "        self.tabular_encoder = TabularEncoder()\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Linear(160, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, image, tabular):\n",
        "        x = torch.cat([\n",
        "            self.image_encoder(image),\n",
        "            self.tabular_encoder(tabular)\n",
        "        ], dim=1)\n",
        "        return self.regressor(x).squeeze()\n",
        "\n",
        "\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df[[\"area\",\"bedrooms\",\"bathrooms\",\"location_score\"]] = scaler.fit_transform(\n",
        "    df[[\"area\",\"bedrooms\",\"bathrooms\",\"location_score\"]]\n",
        ")\n",
        "\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    HousingDataset(train_df, IMAGE_DIR, transform),\n",
        "    batch_size=8, shuffle=True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    HousingDataset(test_df, IMAGE_DIR, transform),\n",
        "    batch_size=8, shuffle=False\n",
        ")\n",
        "\n",
        "# TRAIN\n",
        "model = MultimodalRegressor().to(DEVICE)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(5):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for images, tabular, prices in train_loader:\n",
        "        images, tabular, prices = images.to(DEVICE), tabular.to(DEVICE), prices.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(model(images, tabular), prices)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/5 | Loss: {total_loss/len(train_loader):.4f}\")\n",
        "\n",
        "#  EVALUATE\n",
        "model.eval()\n",
        "preds, targets = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, tabular, prices in test_loader:\n",
        "        images, tabular = images.to(DEVICE), tabular.to(DEVICE)\n",
        "        outputs = model(images, tabular)\n",
        "        preds.extend(outputs.cpu().numpy())\n",
        "        targets.extend(prices.numpy())\n",
        "\n",
        "mae = mean_absolute_error(targets, preds)\n",
        "rmse = np.sqrt(mean_squared_error(targets, preds))\n",
        "\n",
        "print(\"\\nFINAL RESULTS\")\n",
        "print(\"MAE :\", round(mae, 2))\n",
        "print(\"RMSE:\", round(rmse, 2))\n"
      ]
    }
  ]
}